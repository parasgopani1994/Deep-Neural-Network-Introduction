This notebooks have been written to understand how to develop a deep neural network with n hidden layers. Activation functions used are Relu and Sigmoid with output layer using Sigmoid 
activation. In order to update parameters on each iteration, gradient descent is used that uses a learning rate and backward propagation. Finally, the model is used to predict
whether the input image is a cat (1) or not (0). 
